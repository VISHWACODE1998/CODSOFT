import streamlit as st

import pandas as pd

import seaborn as sns

import matplotlib.pyplot as plt

from sklearn.linear_model import LogisticRegression

from sklearn.ensemble import RandomForestClassifier

from sklearn.svm import SVC

from sklearn.neighbors import KNeighborsClassifier

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import StandardScaler

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc

from imblearn.over_sampling import SMOTE

import numpy as np



# Load your dataset

@st.cache_data

def load_data():

    data = pd.read_csv("C:\\Users\\BOBY\\Desktop\\Project\\creditcard.csv")

           return data



                  data = load_data()



# Sidebar - Model selection and settings

                         st.sidebar.title("Credit Card Fraud Detection")

                         st.sidebar.write("Choose model and settings")



# Model selection dropdown in the sidebar

                         model_choice = st.sidebar.selectbox("Select a model to train", ['Logistic Regression', 'Random Forest', 'Support Vector Machine', 'K-Nearest Neighbors'])



# Preprocess the data

                                        st.title("Credit Card Fraud Detection System")

                                        tab1, tab2, tab3 = st.tabs(["Data Overview", "Model Training", "Custom Prediction"])



                                            with tab1:

                                                st.header("Data Overview")

                                                st.write(data.head(10))



# Describe the dataset

                                                st.write("### Dataset Description")

                                                st.write("**Shape of Dataset**: ", data.shape)

                                                st.write("**Columns and Data Types**: ", data.dtypes)

                                                st.write("**Null Values in Each Column**: ", data.isnull().sum())

                                                st.write("**Categorical Columns**: ", data.select_dtypes(include=['object']).columns)



# Show data dimensionality

                                                st.write("### Data Dimensionality Check")

                                                st.write(f"Number of Rows: {data.shape[0]}")

                                                st.write(f"Number of Columns: {data.shape[1]}")



# Display dimensionality of the data

                                                st.write("The data has a dimensionality of: ", f"{data.shape[0]} rows and {data.shape[1]} columns.")



# Null value heatmap

                                                st.write("### Heatmap of Null Values")

                                                fig, ax = plt.subplots(figsize=(12, 8))

                                                        sns.heatmap(data.isnull(), cbar=False, cmap='viridis', ax=ax)

                                                        ax.set_title("Null Value Heatmap")

                                                        st.pyplot(fig)



# Preprocessing the data

                                                        st.write("### Preprocessing the data...")

                                                        data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))

                                                                data['normTime'] = StandardScaler().fit_transform(data['Time'].values.reshape(-1, 1))

                                                                        data = data.drop(['Time', 'Amount'], axis=1)



                                                                                X = data.drop('Class', axis=1)

                                                                                        y = data['Class']



# Handle class imbalance with SMOTE

                                                                                                sm = SMOTE(random_state=42)

                                                                                                        X_res, y_res = sm.fit_resample(X, y)



# Split the dataset into train and test sets

                                                                                                                X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)



# Feature correlation heatmap

                                                                                                                        st.write("### Feature Correlation Heatmap")

                                                                                                                        fig, ax = plt.subplots(figsize=(12, 8))

                                                                                                                                sns.heatmap(data.corr(), annot=False, cmap="coolwarm", ax=ax)

                                                                                                                                ax.set_title("Feature Correlation")

                                                                                                                                st.pyplot(fig)



# Plot features extracted and used for model training

                                                                                                                                st.write("### Features Extracted and Used for Training")

                                                                                                                                num_features = X.shape[1]  # Number of features before removing 'Class'

                                                                                                                                        extracted_features = X.columns



                                                                                                                                                fig, ax = plt.subplots()

                                                                                                                                                        sns.barplot(x=extracted_features, y=[1] * len(extracted_features), ax=ax)

                                                                                                                                                        ax.set_title("Features Extracted for Training")

                                                                                                                                                        ax.set_ylabel('Count')

                                                                                                                                                        ax.set_xlabel('Feature Names')

                                                                                                                                                        ax.set_xticklabels(extracted_features, rotation=90)

                                                                                                                                                        st.pyplot(fig)



# Plot the data split for training and testing

                                                                                                                                                        st.write("### Data Split (Training vs Testing Data)")

                                                                                                                                                        train_size = len(X_train) / len(X_res) * 100

                                                                                                                                                                test_size = len(X_test) / len(X_res) * 100

                                                                                                                                                                        fig, ax = plt.subplots()

                                                                                                                                                                                ax.pie([train_size, test_size], labels=[f"Training Data: {train_size:.2f}%", f"Testing Data: {test_size:.2f}%"], autopct='%1.1f%%', startangle=90)

                                                                                                                                                                                ax.set_title("Training vs Testing Data Split")

                                                                                                                                                                                st.pyplot(fig)



# Scatter plot for linearity check

                                                                                                                                                                                st.write("### Scatter Plot: Checking for Linearity")

                                                                                                                                                                                fig, ax = plt.subplots(figsize=(8, 6))

                                                                                                                                                                                        sns.scatterplot(x=X_res['V1'], y=X_res['V2'], ax=ax)

                                                                                                                                                                                        ax.set_title("Scatter Plot of V1 vs V2")

                                                                                                                                                                                        ax.set_xlabel('V1')

                                                                                                                                                                                        ax.set_ylabel('V2')

                                                                                                                                                                                        st.pyplot(fig)



# Linear vs Non-linear Data

                                                                                                                                                                                        st.write("### Is the Data Linear or Non-Linear?")

                                                                                                                                                                                        corr = X_res.corr()

                                                                                                                                                                                                linearity = "Linear" if corr.abs().mean().mean() > 0.5 else "Non-Linear"

                                                                                                                                                                                                                st.write(f"The data appears to be: **{linearity}** based on feature correlation.")



# Add Standardization Visualization (SMOTE ke baad ka)

                                                                                                                                                                                                                st.write("### Standardization Overview After SMOTE")

# After SMOTE, Standardization of 'normAmount' and 'normTime'

                                                                                                                                                                                                                st.write("Below is the distribution of the features after SMOTE and standardization.")



# Plotting the distribution after standardization

                                                                                                                                                                                                                fig, ax = plt.subplots(figsize=(12, 6))

                                                                                                                                                                                                                        sns.histplot(X_res['V1'], kde=True, label="Standardized V1", ax=ax, color="blue", stat="density", linewidth=0)

                                                                                                                                                                                                                        sns.histplot(X_res['V2'], kde=True, label="Standardized V2", ax=ax, color="green", stat="density", linewidth=0)

                                                                                                                                                                                                                        ax.set_title("Standardized Features Distribution After SMOTE")

                                                                                                                                                                                                                        ax.legend()

                                                                                                                                                                                                                        st.pyplot(fig)



                                                                                                                                                                                                            with tab2:

                                                                                                                                                                                                                        st.header("Train the Model")



# Initialize session state for tracking if the model is trained

                                                                                                                                                                                                            if 'is_trained' not in st.session_state:

                                                                                                                                                                                                                        st.session_state.is_trained = False  # Track whether the model is trained



                                                                                                                                                                                                                    if 'model' not in st.session_state:

                                                                                                                                                                                                                                    st.session_state.model = None  # Track the trained model



# Train the selected model

                                                                                                                                                                                                                                            if st.button("Train and Predict"):

                                                                                                                                                                                                                                                    with st.spinner(f"Training the {model_choice} model..."):

# Model options

                                                                                                                                                                                                                                                    models = {

'Logistic Regression':

                    LogisticRegression(max_iter=1000),

'Random Forest':

                    RandomForestClassifier(),

'Support Vector Machine':

                    SVC(probability=True),

'K-Nearest Neighbors':

                    KNeighborsClassifier()

                }

st.session_state.model = models[model_choice]

                         st.session_state.model.fit(X_train, y_train)



# Set the flag to True after training

                         st.session_state.is_trained = True



# Make predictions

                                 y_pred = st.session_state.model.predict(X_test)

                                                         y_pred_proba = st.session_state.model.predict_proba(X_test)[:, 1] if model_choice != 'K-Nearest Neighbors' else None



# Evaluate the model

                                                                     accuracy = accuracy_score(y_test, y_pred)

                                                                                 st.success(f"Model Trained Successfully! Accuracy: {accuracy * 100:.2f}%")



                                                                                 st.write("### Confusion Matrix")

                                                                                 cm = confusion_matrix(y_test, y_pred)

                                                                                         fig, ax = plt.subplots()

                                                                                                 sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)

                                                                                                 st.pyplot(fig)



                                                                                                 st.write("### Classification Report")

                                                                                                 st.text(classification_report(y_test, y_pred))



# ROC Curve

                                                                         if y_pred_proba is not None:

                                                                                                 fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

                                                                                                             roc_auc = auc(fpr, tpr)



                                                                                                                     st.write("### ROC Curve")

                                                                                                                     fig, ax = plt.subplots()

                                                                                                                             ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')

                                                                                                                             ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')

                                                                                                                             ax.set_xlim([0.0, 1.0])

                                                                                                                             ax.set_ylim([0.0, 1.05])

                                                                                                                             ax.set_xlabel('False Positive Rate')

                                                                                                             
